{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sm\n",
    "\n",
    "# Specify the ARN of the model package you will be using. You can get this\n",
    "# from the sagemaker console after you subscribe to the model package.\n",
    "model_package_arn = 'arn:aws:sagemaker:us-east-2:214666064132:model-package/trends-styles-important-basic'\n",
    "\n",
    "\n",
    "# This notebook creates an endpoint for realtime inference. You may replace the folmaylowing with any name you like. \n",
    "endpoint_name = 'prosper-test-endpoint'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realtime Inference Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# Create model from model package\n",
    "model = sm.ModelPackage(\n",
    "            role=sm.get_execution_role(),\n",
    "            model_package_arn=model_package_arn,\n",
    "            sagemaker_session=sm.Session())\n",
    "\n",
    "# Deploy the model to an endpoint. Be sure to delete the endpoint when you are finished with it.\n",
    "# By default, this method waits until the endpoint is deployed. This could take a while.\n",
    "# To have the API return immediately, set the wait parameter to false.\n",
    "model.deploy(1, 'ml.m4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use endpoint created above to do realtime prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 0.5500407218933105\n"
     ]
    }
   ],
   "source": [
    "# create predictor for endpoint created above0\n",
    "predictor = sm.predictor.RealTimePredictor(endpoint_name, content_type='text/csv')\n",
    "\n",
    "# Sample request\n",
    "# Female\n",
    "gender = 0\n",
    "# Age Range: 18-24\n",
    "age_range = 1\n",
    "# Household Income: $75,000 to $79,999\n",
    "household_income_range = 14\n",
    "\n",
    "# format request data as comma-delimited string\n",
    "request_data = f'{gender},{age_range},{household_income_range}'\n",
    "\n",
    "# Submit the request to the endpoint.\n",
    "# By default, the result is returned as a sequence of bytes. We decode it as utf-8 string.\n",
    "# Note that there are parameters available for serializing and deserializing input and output data.\n",
    "result = predictor.predict('1,2,2').decode('utf-8')\n",
    "\n",
    "# print the result. This is the probability that the person with the requested parameters are in the\n",
    "# target class.\n",
    "print(f'Probability: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.session.Session().delete_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Whole File with Batch Transform Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform input: s3://sagemaker-us-east-2-214666064132/prosper-sample-data/basic-test-data/basic_test_data.csv\n"
     ]
    }
   ],
   "source": [
    "# A sample input file (data/basic_test_data.csv) is provided with this notebook.\n",
    "# The transform job expects its input file to to live in S3.  We upload the file\n",
    "# to the default bucket with key_prefix of prosper-sample-data/basic-test-data. You\n",
    "# can upload to any bucket and key you like if you specify the bucket and key_prefix parameters.\n",
    "\n",
    "transform_input = sm.Session().upload_data('data/basic_test_data.csv', key_prefix='prosper-sample-data/basic-test-data')\n",
    "print(f'transform input: {transform_input}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform output: s3://sagemaker-us-east-2-214666064132/trends-styles-important-basic-2019-11-2-2019-11-22-18-17-23-276\n"
     ]
    }
   ],
   "source": [
    "# Create model from model package\n",
    "model = sm.ModelPackage(\n",
    "            role=sm.get_execution_role(),\n",
    "            model_package_arn=model_package_arn,\n",
    "            sagemaker_session=sm.Session())\n",
    "\n",
    "# Create the transformer\n",
    "# A variety of parameters may be specified here including the output path where\n",
    "# SageMaker will send the results of the transform. Since we do not specify the output,\n",
    "# Sagemaker will leave the results in the default bucket. We will retrieve this location \n",
    "# below so that we can inspect the output.\n",
    "transformer = model.transformer(1, 'ml.m4.xlarge')\n",
    "\n",
    "# Run the transform job.\n",
    "# By default, the output file contains only the inference result for each row.\n",
    "# You can use the output_filter parameter to include any of the input columns. Review also\n",
    "# input_filter which allows you to filter the parameters passed as input to the transformer.\n",
    "# The combination of input_filter and output_filter gives you a lot of flexibility.\n",
    "# By default, the API does not wait for the transform job to complete. You can control this with\n",
    "# the wait parameter.\n",
    "transformer.transform(transform_input, content_type='text/csv')\n",
    "\n",
    "# The transform job sets the output path in the output_path member.\n",
    "print(f'Transform output: {transformer.output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
